#!/usr/bin/env python3
"""
XML íŒŒì¼ë“¤ì´ ì‹¤ì œë¡œ ë™ì¼í•œì§€ í™•ì¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import hashlib
from pathlib import Path

def get_file_hash(filepath):
    """íŒŒì¼ì˜ SHA256 í•´ì‹œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    sha256_hash = hashlib.sha256()
    with open(filepath, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def compare_files(file_groups):
    """íŒŒì¼ ê·¸ë£¹ë“¤ì„ ë¹„êµí•©ë‹ˆë‹¤."""
    mjcf_dir = Path("skillmimic/data/assets/mjcf")

    for group_name, files in file_groups.items():
        print(f"\n{'='*70}")
        print(f"Group: {group_name}")
        print('='*70)

        hashes = {}
        all_same = True
        reference_hash = None

        for filename in files:
            filepath = mjcf_dir / filename
            if not filepath.exists():
                print(f"  âŒ {filename}: FILE NOT FOUND")
                continue

            file_hash = get_file_hash(filepath)
            file_size = filepath.stat().st_size

            # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
            if reference_hash is None:
                reference_hash = file_hash
                print(f"  ğŸ“„ {filename}")
                print(f"     â”œâ”€ Hash: {file_hash[:16]}...")
                print(f"     â””â”€ Size: {file_size:,} bytes")
            else:
                is_same = (file_hash == reference_hash)
                symbol = "âœ…" if is_same else "âŒ"
                print(f"  ğŸ“„ {filename}")
                print(f"     â”œâ”€ Hash: {file_hash[:16]}...")
                print(f"     â”œâ”€ Size: {file_size:,} bytes")
                print(f"     â””â”€ {symbol} {'SAME' if is_same else 'DIFFERENT'}")

                if not is_same:
                    all_same = False

            hashes[filename] = file_hash

        # ê²°ê³¼ ìš”ì•½
        print(f"\n  {'ğŸ‰ All files are IDENTICAL!' if all_same else 'âš ï¸  Files are DIFFERENT!'}")

        # íŒŒì¼ë“¤ ê°„ì˜ ì°¨ì´ í™•ì¸
        if not all_same:
            unique_hashes = {}
            for filename, file_hash in hashes.items():
                if file_hash not in unique_hashes:
                    unique_hashes[file_hash] = []
                unique_hashes[file_hash].append(filename)

            print(f"\n  Unique file groups: {len(unique_hashes)}")
            for i, (hash_val, filenames) in enumerate(unique_hashes.items(), 1):
                print(f"    Group {i}:")
                for fn in filenames:
                    print(f"      - {fn}")

if __name__ == "__main__":
    # í™•ì¸í•  íŒŒì¼ ê·¸ë£¹ë“¤
    file_groups = {
        "ParaHome Standard (ê¸°ë³¸ ì‹ ì²´ ë¹„ìœ¨)": [
            "mocap_parahome_boxhand.xml",
            "mocap_parahome_boxhand_multiobj.xml",
            "mocap_parahome_boxhand_refobj.xml",
            "mocap_parahome_boxhand_hist.xml",
            "mocap_parahome_boxhand_multirefobj.xml",
        ],
        "ParaHome S22 (Subject 22 ì‹ ì²´ ë¹„ìœ¨)": [
            "mocap_parahome_boxhand_s22.xml",
            "mocap_parahome_boxhand_refobj_s22.xml",
            "mocap_parahome_boxhand_hist_s22.xml",
        ],
        "Humanoid (ë¹„êµìš©)": [
            "mocap_humanoid.xml",
            "mocap_humanoid_boxhand.xml",
        ],
    }

    print("\nğŸ” Checking XML file duplicates...")
    compare_files(file_groups)
    print("\n" + "="*70)
    print("Done!")
    print("="*70 + "\n")
